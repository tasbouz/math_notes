\babel@toc {english}{}
\contentsline {chapter}{\numberline {1}Deep Learning: Models}{3}{chapter.1}%
\contentsline {section}{\numberline {1.1}Convolutional Neural Networks}{3}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}Building A Convolutional Neural Network}{3}{subsection.1.1.1}%
\contentsline {subsection}{\numberline {1.1.2}Convolutional Neural Network Architectures}{8}{subsection.1.1.2}%
\contentsline {subsubsection}{\numberline {1.1.2.1}LeNet}{8}{subsubsection.1.1.2.1}%
\contentsline {subsubsection}{\numberline {1.1.2.2}AlexNet}{9}{subsubsection.1.1.2.2}%
\contentsline {subsubsection}{\numberline {1.1.2.3}ZFNet}{9}{subsubsection.1.1.2.3}%
\contentsline {subsubsection}{\numberline {1.1.2.4}VGGNet}{9}{subsubsection.1.1.2.4}%
\contentsline {subsubsection}{\numberline {1.1.2.5}GoogLeNet}{9}{subsubsection.1.1.2.5}%
\contentsline {section}{\numberline {1.2}Word Embedding}{10}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}One-Hot Representation}{10}{subsection.1.2.1}%
\contentsline {subsection}{\numberline {1.2.2}Distributed Representation}{10}{subsection.1.2.2}%
\contentsline {subsection}{\numberline {1.2.3}Word2vec}{11}{subsection.1.2.3}%
\contentsline {subsubsection}{\numberline {1.2.3.1}Continuous Bag-Of-Words (CBOW)}{12}{subsubsection.1.2.3.1}%
\contentsline {subsubsection}{\numberline {1.2.3.2}Continuous Skip-Gram}{13}{subsubsection.1.2.3.2}%
\contentsline {section}{\numberline {1.3}Recurrent Neural Networks}{15}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Building A Recurrent Neural Network}{16}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}Backpropagation Through Time}{18}{subsection.1.3.2}%
\contentsline {subsection}{\numberline {1.3.3}Long Short Term Memory (LSTM)}{21}{subsection.1.3.3}%
