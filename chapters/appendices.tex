\chapter{Constrained Optimization} \label{Constrained Optimization}

Constrained optimization is the problem of finding a minimum (or maximum) of a function $f(x)$ called the \say{objective function}, subject to a number of constraints of the following types:
\bit
\item $h_{i}(x) =0, \:\:\: i=1,2,\ldots$ called \say{equality constraints}
\item $g_{i}(x) \leq 0, \:\:\: i=1,2,\ldots$ called \say{inequality constraints}
\eit

Let's start first with the equality constraints and the we will add inequality constraints.

\section{Equality Constrained Optimization}

The formulation of the optimization problem is to optimize $f(x)$ subject to $h_{i}(x) = 0, \:\:\: i=1,2,\ldots$. Let's assume for simplicity only one constraint $h_{1}(x) = h(x) = 0$. The idea here is that the point that $f(x)$ touches $h(x)$ is the point that $f(x)$ is minimum (or maximum) while the constraint is also valid. At that point $f(x)$ is parallel to $h(x)$ and the tangents $\nabla_{\boldsymbol{w}} f(x)$ and $\nabla_{\boldsymbol{w}} h(x)$ which are perpendicular to $f(x)$ and $h(x)$ respectively, are also parallel to each other. Hence, since  $\nabla_{\boldsymbol{w}} f(x)$ and  $\nabla_{\boldsymbol{w}} h(x)$  are parallel this translates to:
\bse
\nabla_{\boldsymbol{w}} f(x) = \mu \nabla_{\boldsymbol{w}} h(x)
\ese

\vspace{3pt}

which is the condition for the $f(x)$ to be minimum (or maximum) while $h(x) = 0$.\\

Without loss of generality the condition for many constraints reads:
\bse
\nabla_{\boldsymbol{w}} f(x) = \sum_{i} \mu_{i} \nabla_{\boldsymbol{w}} h_{i}(x)
\ese

or by bringing everything in one side:
\begin{align*}
& \nabla_{\boldsymbol{w}} f(x) - \sum_{i} \mu_{i} \nabla_{\boldsymbol{w}} h_{i}(x) = 0 \\
& \nabla_{\boldsymbol{w}} (f(x) - \sum_{i} \mu_{i} h_{i}(x)) = 0 
\end{align*}

At this point we define the \say{Lagrangian} as follows:
\bse
\mathcal{L}(x, \mu_{i}) = f(x) + \sum_{i} \mu_{i} h_{i}(x)
\ese

where $\mu_{i}$ are called \say{Lagrange multipliers}. Subsequently the necessary conditions for optimization of $ \mathcal{L}$ turns to:
\bse
\nabla_{\boldsymbol{w}} \mathcal{L} = 0 \:\:\: \text{and} \:\:\: \frac{\partial \mathcal{L}}{\partial \mu_{i}} = 0
\ese

The solution of this system of equations minimizes (or maximizes) $f(x)$ subject to $h_{i}(x) = 0, \:\:\: \forall i$.

\section{Equality \& Inequality Constrained Optimization}

Now on top of equality constraints we also have inequality constraints. The formulation of the optimization problem is to optimize $f(x)$ subject to $h_{i}(x) = 0, \:\:\: i=1,2,\ldots$ and $g_{i}(x) \leq 0, \:\:\: i=1,2,\ldots$. Following a similar way of thinking as before, although a bit more technical, we can show (but we won't) that if the following four conditions, called \say{Karush - Kuhn - Talker conditions} (KKT), hold:
\bit
\item $h_{i}(x) = 0, \:\:\: \forall i$
\item $g_{i}(x) \leq 0, \:\:\: \forall i$
\item $\lambda_{i} \leq 0, \:\:\: \forall i$
\item $\lambda_{i} g_{i}(x) = 0, \:\:\: \forall i$
\eit

then there exist constants $\mu_{i}$ and $\lambda_{i}$ called \say{KKT multipliers} such that:
\bse
\nabla_{\boldsymbol{w}} f(x) = \sum_{i} \mu_{i} \nabla_{\boldsymbol{w}} h_{i} (x) + \sum_{i} \lambda_{i} \nabla_{\boldsymbol{w}} g_{i}(x)
\ese

By following the same philosophy as for the equality constrained optimization we define the \say{Lagrangian} as follows:
\bse
\mathcal{L}(x, \mu_{i}, \lambda_{i}) = f(x) + \sum_{i} \mu_{i} h_{i} (x) + \sum_{i} \lambda_{i} g_{i}(x)
\ese

and the necessary conditions for optimization of $ \mathcal{L}$ turn to:
\bse
\nabla_{\boldsymbol{w}} \mathcal{L} = 0 \:\:\: \text{and} \:\:\: \frac{\partial \mathcal{L}}{\partial \mu_{i}} = 0 \:\:\: \text{and} \:\:\: \frac{\partial \mathcal{L}}{\partial \lambda_{i}} = 0
\ese

This final form of the optimization problem is usually called the \say{dual optimization problem}. \v

This is the most general case of constrained optimization. If there are no equality constraints $h_{i}(x)$  then we simply have a theory for inequality constrained optimization. If there are no inequality constraints $g_{i}(x)$ then the whole theory turns to the equality constrained optimization problem we developed previously and the KKT multipliers turn to Lagrangian multipliers. Finally, if there are no equality constraints $h_{i}(x)$ neither inequality constraints $g_{i}(x)$ the theory is just a usual optimization problem where we just find the solution where the derivative of $f(x)$ is zero.

\chapter{Kernels} \label{Kernels}

\bd [Kernel]
Let $\bar{x}$ and $\bar{x}^\prime$ be two vectors of space $X$ and $\Phi$ a non-linear transformation. We define $\bar{z}$ and $\bar{z}^\prime$ as the transformed vectors  $\Phi(\bar{x})$ and $\Phi(\bar{x}^\prime)$:
\begin{align*}
& \bar{x} \in X \xrightarrow{\text{$\Phi$}} \bar{z} = \Phi(\bar{x}) \in Z \\
& \bar{x}^\prime \in X \xrightarrow{\text{$\Phi$}} \bar{z}^\prime = \Phi(\bar{x}^\prime) \in Z
\end{align*}

We define the \textbf{kernel} of space $Z$ as the function that is equal to the inner product of the transformation vectors:
\bse
K(\bar{x}, \bar{x}^\prime) = \bar{z}^T \bar{z}^\prime
\ese
\ed

Let's for example assume the following non-linear transformation:
\begin{align*}
& \bar{x} = (x_1, x_2) \xrightarrow{\text{$\Phi$}} \bar{z} = \Phi(\bar{x}) = (1, x_1^2, x_2^2, \sqrt{2} x_1, \sqrt{2} x_2, \sqrt{2} x_1 x_2) \\
& \bar{x}^\prime = (x_1^\prime, x_2^\prime) \xrightarrow{\text{$\Phi$}} \bar{z}^\prime = \Phi(\bar{x}^\prime) = (1, x_1^{2^\prime}, x_2^{2^\prime}, \sqrt{2} x_1^\prime, \sqrt{2} x_2^\prime, \sqrt{2} x_1^\prime x_2^\prime)
\end{align*}

Then for the inner product:
\bse
\bar{z}^T \bar{z}^\prime = 1 + x_1^2 x_1^{2^\prime} + x_2^2 x_2^{2^\prime} + 2 x_1  x_1^\prime + 2 x_2 x_2^\prime + 2 x_1 x_2 x_1^\prime x_2^\prime
\ese

However we can get to the same result by simply defining a Kernel of the form:
\begin{align*}
K(\bar{x}, \bar{x}^\prime) &= (1 + \bar{x} \bar{x}^\prime)^2 \\
&= (1 + x_1 x_1^\prime + x_2 x_2^\prime )^2 \\
&= 1 + x_1^2 x_1^{2^\prime} + x_2^2 x_2^{2^\prime} + 2 x_1 x_1^\prime + 2 x_2 x_2^\prime + 2 x_1 x_2 x_1^\prime x_2^\prime
\end{align*}

Hence by knowing the Kernel of a space $Z$ of some non-linear transformation $\Phi$ we can compute inner products without the need of transforming vectors from $X$ to $Z$.\\

The kernel trick is to use this idea in the opposite direction. Namely, to assume that a function $K(\bar{x}, \bar{x}^\prime)$ is the kernel of some space $Z$ for some non-linear transformation $\Phi$ and to compute inner products without even knowing the transformation.\\

The question that arises is how do we know that some function $K(\bar{x}, \bar{x}^\prime)$ is actually the kernel of a space $Z$. There are three approaches to this problem:
\begin{enumerate}
\item By construction (as we did in the example above).
\item By Mercer's condition that states that $K(\bar{x}, \bar{x}^\prime)$ is a valid kernel for some space $Z$ if
\bse
\int K(\bar{x}, \bar{x}^\prime) g(\bar{x}) g(\bar{x}^\prime) d\bar{x} d\bar{x}^\prime \geq 0 \:\:\: \forall \:\:\: \text{square integrable functions} \:\:\: g(\bar{x})
\ese
\item Sometimes we don't care if $K(\bar{x}, \bar{x}^\prime)$ is a valid kernel for some space $Z$ as long as it does the job.
\end{enumerate}

\chapter{Applied Machine Learning}

In this section we will cover the applied side of machine learning.  This checklist can guide you through your machine learning projects.  There are eight main steps:

\begin{enumerate}
\item \textbf{Frame The Problem}
	\bit
	\item Define the objective in business terms.
	\item How will your solution be used?
	\item What are the current solutions/workarounds (if any)?
	\item How should you frame this problem (supervised/unsupervised, online/offline, etc)?
	\item How should performance be measured?
	\item Is the performance measure aligned with the business objective?
	\item What would be the minimum performance needed to reach the business objective?
	\item What are comparable problems? Can you reuse experience or tools?
	\item Is human expertise available? How would you solve the problem manually?
	\item List the assumptions you (or others) have made so far and verify them if possible.
	\eit
	
\item \textbf{Get The Data}
	\bit
	\item List the data you need and how much you need.
	\item Find and document where you can get that data.
	\item Check how much space it will take.
	\item Check legal obligations, and get access authorization if necessary.
	\item Create a workspace (with enough storage space).
	\item Get the data.
	\item Make sure you data are not of insufficient quantity,  poor quality,  or non representative of the population.  Especially validation and test set must be as representative as possible..
	\item Convert the data to a format you can easily manipulate (without changing the data itself).
	\item Ensure sensitive information is deleted or protected (e.g anonymized).
	\item Make a copy of the original dataset and work with this one.
	\item Automate as much as possible so you can easily get fresh data.
	\eit
	
\item \textbf{Explore The Data}
	\bit
	\item Create a Jupyter notebook to keep a record of your data exploration.
	\item Study each attribute and its characteristics: 	name, type, percentage of missing values,  noisiness and type of noise,  outliers, usefulness for the task basic statistics (mean,  standard deviation,  type of distribution, etc).
	\item For supervised learning tasks, identify the target attribute(s).
	\item Sample a test set,  put it aside,  and never look at it (stratify if needed).
	\item Visualize the data.
	\item Study the correlations between attributes.
	\item Study how you would solve the problem manually.
	\item Identify extra data that would be useful.
	\item Document what you have learned.
	\item Try to get insights from a field expert for these steps.
	\eit

\item	 \textbf{Prepare The Data}
	\bit
	\item Write functions for all data transformations you apply,  for the following reasons:
		\bit
		\item So you can easily prepare the data the next time you get a fresh dataset.
		\item So you can apply these transformations in future projects.
		\item To clean and prepare the test set.
		\item To clean and prepare new data instances once your solution is live.
		\item To make it easy to treat your preparation choices as hyperparameters.
		\eit
	\item Clean the data: fix or remove outliers,  fill in missing values (e.g with zero, mean, median,etc)  or drop their rows (or columns).
	\item Feature selection/engineering:
		\bit
		\item Drop the attributes that provide no useful information for the task.
		\item Drop variables that have a very high percentage of missing values.
		\item Drop variables that have a very low variation (i.e not too much information).
		\item Drop variables that have very low correlation with the target.
		\item Find variables that are highly correlated with each other (i.e same behaviour),  and keep the ones that have higher correlation with the target (drop the other ones).
		\item Identify the promising transformations you may want to apply (e.g combine existing features to produce more useful ones or add promising transformations of features).
		\item Select best features based on a metric.  Either start with one variable and add more (forward selection),  or start with all variables and eliminate (backward elimination or recursive feature elimination).
		\item Discretize continuous features.
		\item Decompose features (e.g categorical,  date/time,  etc).
		\item Standardize or normalize features (feature scaling).  Machine learning algorithms don't perform well when the input numerical attributes have very different scales.  There are two common ways to get all attributes to have the same scale: normalization and standardization.  In normalization the values are shifted and rescaled so that they end up ranging from 0 to 1.  We do this by subtracting the minimum value and dividing by the maximum minus the minimum. Standardization first subtracts the mean value (so standardized values always have a zero mean),  and then divides by the standard deviation so that the resulting distribution has unit variance.  Unlike normalization,  standardization does not bound values to a specific range,  which may be a problem for some algorithms.  However, standardization is much less affected by outliers. 
		\eit
	\eit

\item \textbf{Shortlist Promising Models}
	\bit
	\item If the data is huge, you may want to sample smaller training sets so you can train many different models in a reasonable time (be aware that this penalizes complex models such as large neural nets or Random Forests). 
	\item Train many quick-and-dirty models from different categories using standard parameters.
	\item Measure and compare their performance.
	\item For each model,  use K-fold cross-validation and compute the mean and standard deviation of the performance measure on the K folds.
	\item Analyze the most significant variables for each algorithm.
	\item Analyze the types of errors the models make. What data would a human have used to avoid these errors?
	\item Shortlist the top three to five most promising models, preferring models that make different types of errors.
	\eit
	
\item \textbf{Fine-Tune The System}
	\bit
	\item You will want to use as much data as possible for this step,  especially as you move toward the end of fine-tuning. 
	\item Fine-tune the hyperparameters using cross-validation.
	\item Try ensemble methods.  Combining your best models will often produce better performance than running them individually.
	\item Once you are confident about your final model,  measure its performance on the test set to estimate the generalization error.
	\item Donâ€™t tweak your model after measuring the generalization error since you would just start overfitting the test set.
	\eit

\item \textbf{Present Your Solution}
	\bit
	\item Document what you have done.
	\item Create a nice presentation.
	\item Make sure you highlight the big picture first.
	\item Explain why your solution achieves the business objective.
	\item Don't forget to present interesting points you noticed along the way.
	\item Describe what worked and what did not.
	\item List your assumptions and your system's limitations.
	\item Ensure your key findings are communicated through beautiful visualizations or easy-to-remember statements.
	\eit

\item \textbf{Launch}
	\bit
	\item Get your solution ready for production.
	\item Write monitoring code to check your system's live performance at regular intervals and trigger alerts when it drops.
	\item Beware of slow degradation: models tend to ``rot" as data evolves.
	\item Measuring performance may require a human pipeline.
	\item Also monitor your inputs' quality.
	\item Retrain your models on a regular basis on fresh data (automate as much as possible).
	\item Keep backups of every model.
	\eit
\end{enumerate}